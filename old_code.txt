# Run MaSIF_ligand_site on all points in pdb, return probablity value for each site
  def getLigandSiteProbs(self):
    ligand_site_pred_list = []
    fullSamples = self.n_samples // minPockets

    print('{} batches to run on ligand_site'.format(fullSamples))
    before_time = process_time()

    for i in range(fullSamples):
      if i % 10 == 0:
        done = 100.0 * i/fullSamples
        print('{} of {} batches completed. {}% done...'.format(i, fullSamples, round(done)))
      sample = range(minPockets * i, minPockets * (i+1))
      temp_X = self.getDataSample(sample)
      temp_pred = tf.sigmoid(tf.squeeze(self.ligand_site_model(temp_X, gen_sample)))
      ligand_site_pred_list.append(temp_pred)

    i = fullSamples
    n_leftover = self.n_samples % minPockets
    valid = tf.range(minPockets * i, minPockets * i + n_leftover)
    #garbage = tf.zeros([minPockets - n_leftover], dtype=tf.int32)
    #sample = tf.expand_dims(tf.concat([valid, garbage], axis=0), axis=0)

    garbage = tf.range(minPockets * (i-1) + n_leftover, minPockets * i)
    sample = tf.expand_dims(tf.concat([garbage, valid], axis=0), axis=0)
    
    temp_X = self.getDataSample(sample)
    temp_pred = tf.sigmoid(tf.squeeze(self.ligand_site_model(temp_X, gen_sample)))
    ligand_site_pred_list.append(temp_pred[-n_leftover:])

    after_time = process_time()
    print('100% of batches completed in {} seconds.'.format(round(after_time - before_time)))

    return tf.concat(ligand_site_pred_list, axis = 0)


    def getFlatDataFromDict(key, sample):
      data = self.data_dict[key]
      return np.take(data, sample, axis=0).flatten()
    def getDataSampleTemp(sample):
      temp_fn = lambda key : getFlatDataFromDict(key, sample)
      flat_list = list(map(temp_fn, data_order))
      return tf.expand_dims(tf.concat(flat_list, axis=0), axis=0)
    self.getDataSample = lambda sample : getDataSampleTemp(sample)
